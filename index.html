<!DOCTYPE html>
<html>
	<!-- Google Tag Manager -->
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-NCZ2NDNR');</script>
	<!-- End Google Tag Manager -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-V8DCPVN6GL"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-V8DCPVN6GL');
	</script>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Yann Labbé</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="keywords" content="Yann Labbé inria ens meta machine learning computer vision robotics">
	<meta name="author" content="Yann Labbé">
	<link rel="stylesheet" href="./scss/style.css">
	<meta name="thumbnail" content="https://ylabbe.github.io/photos/picture.jpg" />
	<PageMap>
    <DataObject type="thumbnail">
      <Attribute name="src" value="https://ylabbe.github.io/photos/picture.jpg"/>
      <Attribute name="width" value="100"/>
      <Attribute name="height" value="130"/>
    </DataObject>
  </PageMap>
</head>

<body>
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-V8DCPVN6GL"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-V8DCPVN6GL');
	</script>

	<div class="container">

		<div class="row pt-3">

			<div class="col-sm-6 col-md-3">
				<img src="./photos/picture.jpg" class="rounded img-fluid" alt="Yann Labbé">
			</div>

			<div class="col-sm-6 col-md-9">
				<h1>Yann Labbé</h1>
					<div class="row pb-3 pt-1">
						<div class="col-sm-12">
							<a style="text-decoration: none" class="pr-1" href="mailto:labbe.yann1994@gmail.com"
								title="e-Mail">
								<img src="./logos/mail.png" height="40" width="40" alt="email"
									style="vertical-align:middle;" border="0"
									onmouseover="this.src=&#39;./logos/mail.png&#39;;"
									onmouseout="this.src=&#39;./logos/mail.png&#39;;">
							</a>
							<a style="text-decoration: none" class="pr-1"
								href="https://scholar.google.com/citations?user=030pukwAAAAJ&hl=en"
								title="Google Scholar"><span style="font: 80% Arial,sans-serif; color:#0783B6;">
									<img src="./logos/scholar.png" height="40" widbh="40" alt="google scholar"
										style="vertical-align:middle;" border="0"
										onmouseover="this.src=&#39;./logos/scholar.png&#39;;"
										onmouseout="this.src=&#39;./logos/scholar.png&#39;;">
								</span></a>
							<a style="text-decoration: none" class="pr-1" href="https://github.com/ylabbe"
								title="GitHub">
								<img src="./logos/github.png" height="40" width="40" alt="github"
									style="vertical-align:middle;" border="0"
									onmouseover="this.src=&#39;./logos/github.png&#39;;"
									onmouseout="this.src=&#39;./logos/github.png&#39;;">
							</a>
							<a style="text-decoration: none" class="pr-1"
								href="https://www.linkedin.com/in/yann-labb%C3%A9-360b1b114" title="LinkedIn">
								<img src="./logos/linkedin.png" height="40" width="40" alt="linkedin"
									style="vertical-align:middle;" border="0"
									onmouseover="this.src=&#39;./logos/linkedin.png&#39;;"
									onmouseout="this.src=&#39;./logos/linkedin.png&#39;;">
							</a>
							<a style="text-decoration: none" class="pr-1"
								href="./resume/resume.pdf" title="">
								<img src="./logos/resume.png" height="40" width="40" alt="linkedin"
									style="vertical-align:middle;" border="0"
									onmouseover="this.src=&#39;./logos/resume.png&#39;;"
									onmouseout="this.src=&#39;./logos/resume.png&#39;;">
							</a>
						</div>
					</div>
			<p align="justify">
				I am interested in multimodal foundation models, robotics and AI agents.
				I was one of the founding researcher of H Company, a research scientist at Meta Reality Labs and an intern in NVIDIA's Seattle Robotics Lab. I obtained a PhD from École Normale Supérieure where I was supervised by <a href="http://people.ciirc.cvut.cz/~sivic/" class="href-link">Josef Sivic</a>.
				<!-- I graduated from <a href="https://ens-paris-saclay.fr/en"> Ecole Normale Supérieure de
					Cachan<a> where I received a dual Masters degree in Mathematics, Machine Learning, Computer Vision <a
							href="http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/"> (MVA)</a> and
						in Electrical Engineering <a
							href="https://www.universite-paris-saclay.fr/formation/master/electronique-energie-electrique-automatique">
							(E3A)</a> with highest honors. In 2017, I was among the top candidates at the nationwide
						competition <a href="https://en.wikipedia.org/wiki/Agr%C3%A9gation"> Agrégation</a> in Electrical
						Engineering. I was an intern at Nvidia in 2022 and Chronocam (now Prophesee) in 2016. Please <a href= "mailto:labbe.yann1994@gmail.com">reach out</a> for a detailed resume. -->
			</p>
			</div>
		</div>



		<hr>
		<h2>Publications</h2>

		Representative publications are highlighted. Also see <a href="https://scholar.google.com/citations?user=030pukwAAAAJ&hl=en" class="href-link"> Google Scholar </a> for an up-to-date list of publications.
		<div class="representative-publication">
			<div class="pub-img">
				<img src="./thumbnails/hai.png" class="thumbnail" alt="surferh">
			</div>
			<div class="pub-details">
				<b>Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights</b>
				<br>
				Mathieu Andreux, Breno Baldas Skuk, Hamza Benchekroun, Emilien Biré, Antoine Bonnet, Riaz Bordie, Nathan Bout, Matthias Brunel, Pierre-Louis Cedoz, Antoine Chassang, Mickaël Chen, Alexandra D. Constantinou, Antoine d'Andigné, Hubert de La Jonquière, Aurélien Delfosse, Ludovic Denoyer, Alexis Deprez, Augustin Derupti, Michael Eickenberg, Mathïs Federico, Charles Kantor, Xavier Koegler, <u>Yann Labbé</u>, Matthew C. H. Lee, Erwan Le Jumeau de Kergaradec, Amir Mahla, Avshalom Manevich, Adrien Maret, Charles Masson, Rafaël Maurin, Arturo Mena, Philippe Modard, Axel Moyal, Axel Nguyen Kerbel, Julien Revelle, Mats L. Richter, María Santos, Laurent Sifre, Maxime Theillard, Marc Thibault, Louis Thiry, Léo Tronchon, Nicolas Usunier, Tony Wu
				<br>
				arXiv 2025
				<div class="pub-hrefs">
					<a href="https://arxiv.org/abs/2506.02865" class="href-paper-link">paper</a>
					<a href="https://runner.hcompany.ai/" class="href-paper-link">product</a>
					<a href="https://github.com/hcompai/surfer-h-cli" class="href-paper-link">agent</a>
					<a href="https://huggingface.co/collections/Hcompany/holo1-683dd1eece7eb077b96d0cbd" class="href-paper-link">Holo1 models (3B/7B)</a>
					<a href="https://huggingface.co/datasets/Hcompany/WebClick" class="href-paper-link">WebClick dataset</a>
				</div>
			</div>
		</div>

		<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/robot.jpg" class="thumbnail" alt="bop24">
			</div>
			<div class="pub-details">
				<b>6D Object Pose Tracking in Internet Videos for Robotic Manipulation</b>
				<br>
				Georgy Ponimatkin, Martin Cífka, Tomas Soucek, Médéric Fourmy, <u>Yann Labbé</u>, Vladimir Petrik, Josef Sivic
				<br>
				ICLR 2025
				<br>
				<div class="pub-hrefs">
					<a href="https://arxiv.org/abs/2503.10307" class="href-paper-link">paper</a>
					<a href="https://ponimatkin.github.io/freepose/" class="href-paper-link">project page</a>
					<a href="https://github.com/ponimatkin/freepose" class="href-paper-link">code</a>
				</div>
			</div>
		</div>

		<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/foundpose.jpg" class="thumbnail" alt="bop24">
			</div>
			<div class="pub-details">
				<b>FoundPose: Unseen Object Pose Estimation with Foundation Features</b>
				<br>
				Evin Pınar Örnek, <u>Yann Labbé</u>, Bugra Tekin, Lingni Ma, Cem Keskin, Christian Forster, Tomas Hodan
				<br>
				ECCV 2024
				<br>
				<div class="pub-hrefs">
					<a href="https://arxiv.org/pdf/2311.18809" class="href-paper-link">paper</a>
					<a href="https://evinpinar.github.io/foundpose/" class="href-paper-link">project page</a>
				</div>
			</div>
		</div>


		<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/bop24.jpg" class="thumbnail" alt="bop24">
			</div>
			<div class="pub-details">
				<b>BOP Challenge 2023 on Detection, Segmentation and Pose Estimation of Seen and Unseen Rigid Objects</b>
				<br>
				Tomas Hodan, Martin Sundermeyer, <u>Yann Labbé</u>, Van Nguyen Nguyen, Gu Wang, Eric Brachmann, Bertram Drost, Vincent Lepetit, Carsten Rother, Jiri Matas
				<br>
				CVPR Workshops 2024
				<br>

				<div class="pub-hrefs">
					<a href="https://openaccess.thecvf.com/content/CVPR2024W/CV4MR/papers/Hodan_BOP_Challenge_2023_on_Detection_Segmentation_and_Pose_Estimation_of_CVPRW_2024_paper.pdf" class="href-paper-link">paper</a>
					<a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2023/" class="href-paper-link">workshop</a>
				</div>
			</div>
		</div>

		<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/focalposepp.jpg" class="thumbnail" alt="FocalPose">
			</div>
			<div class="pub-details">

				<b>FocalPose++: Focal Length and Object Pose Estimation via Render and Compare</b>
				<br>
				Martin Cífka, Georgy Ponimatkin, <u>Yann Labbé</u>, Bryan Russell, Mathieu Aubry, Vladimir Petrik, Josef Sivic
				<br>
				TPAMI 2024
				<br>
				<div class="pub-hrefs">
					<a href="https://arxiv.org/abs/2312.02985" class="href-paper-link">  paper</a>
				</div>
			</div>
		</div>

		<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/phdthesis.png" class="thumbnail" alt="PhD thesis">
			</div>
			<div class="pub-details">

				<b>Pose estimation of rigid objects and robots</b>
				<br>
				<u>Yann Labbé</u>
				<br>
				PhD Thesis, 2023
				<br>

				<div class="pub-hrefs">
					<a href="https://hal.science/tel-04124865/" class="href-paper-link">link</a>
				</div>

			</div>
		</div>

	<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/bop22.jpg" class="thumbnail" alt="bop24">
			</div>
			<div class="pub-details">
				<b>BOP Challenge 2022 on Detection, Segmentation and Pose Estimation of Specific Rigid Objects</b>
				<br>
				Martin Sundermeyer, Tomas Hodan, <u>Yann Labbé</u>, Gu Wang, Eric Brachmann, Bertram Drost, Carsten Rother, Jiri Matas
				<br>
				CVPR Workshops 2023
				<br>

				<div class="pub-hrefs">
					<a href="https://openaccess.thecvf.com/content/CVPR2023W/CV4MR/papers/Sundermeyer_BOP_Challenge_2022_on_Detection_Segmentation_and_Pose_Estimation_of_CVPRW_2023_paper.pdf" class="href-paper-link">paper</a>
					<a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2022/" class="href-paper-link">workshop</a>
				</div>
			</div>
		</div>

		<div class="representative-publication">
			<div class="pub-img">
				<img src="./thumbnails/megapose.jpg" class="thumbnail" alt="MegaPose">
			</div>
			<div class="pub-details">

				<b>MegaPose: 6D Pose Estimation of Novel Objects via Render & Compare</b>
				<br>
				<u>Yann Labbé</u>, Lucas Manuelli, Arsalan Mousavian, Stephen Tyree, Stan Birchfield, Jonathan Tremblay,
				Justin Carpentier, Mathieu Aubry, Dieter Fox, Josef Sivic
				<br>
				CoRL 2022
				<br>

				<div class="pub-hrefs">
					<a href="https://arxiv.org/abs/2212.06870" class="href-paper-link">paper</a>
					<a href="https://megapose6d.github.io/" class="href-paper-link">project
							page</a>
					<a href="https://github.com/megapose6d/megapose6d" class="href-paper-link">code</a>
					<a href="https://openreview.net/forum?id=1zbWQxFIU-" class="href-paper-link">
							openreview </a>
				</div>

			</div>
		</div>

		<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/focalpose.jpg" class="thumbnail" alt="FocalPose">
			</div>
			<div class="pub-details">

				<b>Focal Length and Object Pose Estimation via Render and Compare</b>
				<br>
				Georgy Ponimatkin, <u>Yann Labbé</u>, Bryan Russel, Mathieu Aubry, Josef Sivic
				<br>
				CVPR 2022
				<br>

				<div class="pub-hrefs">
					<a href="https://arxiv.org/abs/2204.05145" class="href-paper-link">  paper
						</a>
					<a href="https://ponimatkin.github.io/focalpose/index.html" class="href-paper-link"> project page  </a>
					<a href="https://github.com/ponimatkin/focalpose" class="href-paper-link"> code
						 </a>
				</div>

			</div>
		</div>

		<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/cosyslam.png" class="thumbnail" alt="CosySLAM">
			</div>
			<div class="pub-details">

				<b>CosySlam: investigating object-level SLAM for detecting locomotion surfaces</b>
				<br>
				César Debeunne, Médéric Fourmy, <u>Yann Labbé</u>, Pierre-Alexandre Léziart, Guilhem Saurel, Joan Solà,
				Nicolas Mansard
				<br>
				arXiv 2022
				<br>

				<div class="pub-hrefs">
					<a href="https://hal.archives-ouvertes.fr/hal-03351438v2" class="href-paper-link">  paper  </a>
				</div>

			</div>
		</div>

		<div class="representative-publication">
			<div class="pub-img">
				<img src="./thumbnails/robopose.png" class="thumbnail" alt="RoboPose">
			</div>
			<div class="pub-details">

				<b>Single-view robot pose and joint angle estimation via render & compare</b><br>
				<u>Yann Labbé</u>, Justin Carpentier, Mathieu Aubry, Josef Sivic<br>
				CVPR 2021
				<br>
				<div class="details-highlight"> Accepted as oral (top 4% submissions). </div>

				<div class="pub-hrefs">
					<a href="https://arxiv.org/abs/2104.09359" class="href-paper-link"> paper
						 </a>
					<a href="https://www.di.ens.fr/willow/research/robopose" class="href-paper-link">  project page  </a>
					<a href="https://github.com/ylabbe/robopose" class="href-paper-link">  code
						 </a>
				</div>

			</div>
		</div>

		<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/cosypose_pami.png" class="thumbnail" alt="CosyPose">
			</div>
			<div class="pub-details">

				<b>CosyPose: Consistent multi-view multi-object 6D pose estimation</b><br>
				<u>Yann Labbé</u>, Justin Carpentier, Mathieu Aubry, Josef Sivic<br>
				arXiv 2021<br>
				Extended version of the ECCV paper <br>

				<div class="pub-hrefs">
					<a href="https://drive.google.com/file/d/1YVemqAEb_aL174XPYD-wag-DW7mUnvzC/view?usp=sharing" class="href-paper-link">
						 paper </a>
				</div>
			</div>
		</div>

		<div class="publication">
			<div class="pub-img">
				<img src="./thumbnails/bop.png" class="thumbnail" alt="BOP">
			</div>

			<div class="pub-details">
				<b>BOP Challenge 2020 on 6D Object Localization</b><br>
				Tomas Hodaň, Martin Sundermeyer, Bertram Drost, <u>Yann Labbé</u>, Eric Brachmann, Frank Michel, Carsten
				Rother, Jiri Matas<br>
				ECCV Workshops 2020<br>

				<div class="pub-hrefs">
					<a href="https://arxiv.org/abs/2009.07378" class="href-paper-link">  paper
						 </a>
					<a href="https://bop.felk.cvut.cz/challenges/bop-challenge-2020/" class="href-paper-link">  website  </a>
					<a href="http://cmp.felk.cvut.cz/sixd/workshop_2020/" class="href-paper-link"> 
							workshop  </a>
				</div>

			</div>
		</div>

		<div class="representative-publication">
			<div class="pub-img">
				<img src="./thumbnails/cosypose.png" class="thumbnail" alt="CosyPose">
			</div>
			<div class="pub-details">

				<b>CosyPose: Consistent multi-view multi-object 6D pose estimation</b><br>
				<u>Yann Labbé</u>, Justin Carpentier, Mathieu Aubry, Josef Sivic<br>
				ECCV 2020<br>
				<div class="details-highlight">
					Winner of the BOP Challenge at ECCV 2020 (5/6 awards).
				</div>


				<div class="pub-hrefs">
					<a href="https://arxiv.org/abs/2008.08465" class="href-paper-link">  paper
						</a>
					<a href="https://www.di.ens.fr/willow/research/cosypose" class="href-paper-link">  project page </a>
					<a href="https://github.com/ylabbe/cosypose" class="href-paper-link"> code
						</a>
					<a href="https://youtu.be/MNH_Ez7bcP0" class="href-paper-link"> video
						</a>
					<a
						href="https://docs.google.com/presentation/d/1jZDu4mw-uNcwzr5jMFlqEddZsb7SjQozXVG3dT6-1M0/edit?usp=sharing" class="href-paper-link">
						BOP slides  </a>
				</div>
			</div>
		</div>

		<div class="representative-publication">
			<div class="pub-img">
				<img src="./thumbnails/mcts.jpg" class="thumbnail" alt="MCTS">
			</div>
			<div class="pub-details">

				<b>Monte-Carlo Tree Search for Efficient Visually Guided Rearrangement Planning</b><br>
				<u>Yann Labbé</u>, Sergey Zagoruyko, Igor Kalevatykh, Ivan Laptev, Justin Carpentier, Mathieu Aubry,
				Josef Sivic<br>
				RAL 2020 <br>

				<div class="pub-hrefs">
					<a href="https://arxiv.org/abs/1904.10348" class="href-paper-link">paper</a>
					<a href="https://ylabbe.github.io/rearrangement-planning/" class="href-paper-link">project
							page</a>
					<a href="https://github.com/ylabbe/rearrangement-planning" class="href-paper-link">code</a>
				</div>
			</div>
		</div>


	</div>
	<div id="b83edd14-d692-4775-a488-9bb3d146dc6d"
		style="position: fixed; z-index: 2147483647; top: 0px; right: 0px; width: auto; height: auto; margin: 0px; padding: 0px; border: none; outline: none; box-shadow: none; background-color: inherit; font-size: 14px; line-height: 1; text-decoration: none; vertical-align: baseline; user-select: none; pointer-events: none; border-radius: 0px;">
	</div>
</body><auto-scroll></auto-scroll>

</html>
